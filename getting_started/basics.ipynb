{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "a = mx.array([1, 2, 3,4])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlx.core.int32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlx.core.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = mx.array([1.0,2.0,3.0,4.0])\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in MLX are lazy. The outputs of MLX are not computed until they are needed. To force an array to be evalated use `eval()`. Arrays will automatically be evaluated in few cases. For example, inspecting a scalar with `array.item()`, printing an array or converting an array from  `array.numpy.ndarray` all automatically evaluate the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([2, 4, 6, 8], dtype=float32)\n",
      "array([2, 4, 6, 8], dtype=float32)\n",
      "array([2, 4, 6, 8], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = a+b  # c is not evaluated yet\n",
    "mx.eval(c)  # c is evaluated now\n",
    "print(c)\n",
    "# or \n",
    "\n",
    "c = a+b # c is not evaluated yet\n",
    "print(c) # c is evaluated now\n",
    "\n",
    "# or\n",
    "\n",
    "c = a+b # c is not evaluated yet\n",
    "import numpy as np\n",
    "np.array(c) # c is evaluated now\n",
    "print(c) # c is evaluated now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function and Graph Transformations\n",
    "\n",
    "MLX has standard function transformations like `grad()` and `vmap()`. Transformations can be composed arbitrarily. For example `grad(vmap(grad(fn)))` is allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mx.array(0.0)\n",
    "mx.sin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.grad(mx.sin)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-0, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.grad(mx.grad(mx.sin))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `mlx.core.grad` returns a function which computes the gradient of `fun`\n",
    "\n",
    "\n",
    "`mlx.core.grad(fun:function, argnums: Optional) -> function`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Lazy Evaluation?\n",
    "\n",
    "When we perform operations in MLX, no computation actually happens. Instead a compute graph is recorded. The actual computation only happens if an `eval()` is performed.\n",
    "\n",
    "MLX uses lazy evaluation because it has some nice features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Computer Graphs\n",
    "\n",
    "Lazy evaluation let us record a compute graph without actually doing any computations. This is useful for function transformations like `grad()` and `vmap()` and graph optimizations.\n",
    "\n",
    "Currently, MLX does not compile and rerun compute graphs. They are all generated dynamically. However, lazy evaluation makes it much easier to integrate compilation for future performance enhancements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Compute What you use!\n",
    "\n",
    "In MLX you do not need to worry much about computing outputs that are never used. Similarly, lazy evaluation can be beneficial for saving memory while keeping the code simple. Say you have a very large model `Model` derived from `mlx.nn.Module`. You can instantiate this model with `model = Model()`. Typically, this will intialize all of the weights as `float32`, but the initialization does not actully computer anything until you perform an `eval()`. If you update the model with `float16` weights, your maximum memory consumend will be half that required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Evaluate?\n",
    "\n",
    "A common question is when to use `eval()`. The trade-off is between letting graphs get too large and not batching enough useful work.\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    a = a+b\n",
    "    mx.eval(a)\n",
    "    b = b*2\n",
    "    mx.eval(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bad idea because there is some fixed overhead with each graph evaluation. On the other hand, there is some slight overhead which grows with the compute graph size, so extremely large graphs (while computationally correct) can be costly.\n",
    "\n",
    "Luckily, a wide range of compute graph sizes work pretty well with MLX: anything from a few tens of operations to many thousands of operations per evaluation should be okay.\n",
    "\n",
    "Most numerical computations have an iterative outer loop (e.g. the iteration in stochastic gradient descent). A natural and usually efficient place to use eval() is at each iteration of this outer loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
